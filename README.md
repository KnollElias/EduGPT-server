
# start local-llm
ollama serve

# start server
cargo run
